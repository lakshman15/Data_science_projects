{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Hi...In this notebook i used exploratory data analysis and Linear,Random forest model for predicting the house prices."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport scipy.stats as st\n\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import metrics\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape , test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = train.select_dtypes(include=[np.number])\nnumeric_features.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1.Temporal Variables(Eg: Datetime Variables)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of variables that contain year information\nyear_feature = [feature for feature in numeric_features if 'Yr' in feature or 'Year' in feature]\n\nyear_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us explore the contents of temporal  variables\nfor feature in year_feature:\n    print(feature, train[feature].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in year_feature:\n    if feature!='YrSold':\n        data=train.copy()\n        ## We will capture the difference between year variable and year the house was sold for\n        data[feature]=data['YrSold']-data[feature]\n\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel( feature)\n        plt.ylabel('SalePrice')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.Discrete Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"discrete_feature=[feature for feature in numeric_features if len(train[feature].unique())<25 and feature not in year_feature + ['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[discrete_feature].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now let us find the relationship between these discrete features and Sale Price"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in discrete_feature:\n    data=train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" #### 3. Continuous Variables:"},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_feature=[feature for feature in numeric_features if feature not in discrete_feature+year_feature+['Id']]\nprint(\"Continuous Feature Count {}\".format(len(continuous_feature)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us analyse the continuous values with data visualisation to understand the data distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in continuous_feature:\n    data=train.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = train.select_dtypes(include=[np.object])\ncategorical_features.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Estimate Skewness and Kurtosis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.skew(), train.kurt()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['SalePrice']\nplt.figure(1); plt.title('Johnson SU')\nsns.distplot(y, kde=False, fit=st.johnsonsu)\nplt.figure(2); plt.title('Normal')\nsns.distplot(y, kde=False, fit=st.norm)\nplt.figure(3); plt.title('Log Normal')\nsns.distplot(y, kde=False, fit=st.lognorm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is apparent that SalePrice doesn't follow normal distribution, so before performing regression it has to be transformed. While log transformation does pretty good job, best fit is unbounded Johnson distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train.skew(),color='blue',axlabel ='Skewness')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,8))\nsns.distplot(train.kurt(),color='r',axlabel ='Kurtosis',norm_hist= False, kde = True,rug = False)\n#plt.hist(train.kurt(),orientation = 'vertical',histtype = 'bar',label ='Kurtosis', color ='blue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(train['SalePrice'],orientation = 'vertical',histtype = 'bar', color ='blue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = np.log(train['SalePrice'])\ntarget.skew()\nplt.hist(target,color='black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = numeric_features.corr()\nprint(correlation['SalePrice'].sort_values(ascending = False),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To explore further we will start with the following visualisation methods to analyze the data better:\n\n - Correlation Heat Map\n - Zoomed Heat Map\n - Pair Plot \n "},{"metadata":{},"cell_type":"markdown","source":"### Correlation Heat Map"},{"metadata":{"trusted":true},"cell_type":"code","source":"f , ax = plt.subplots(figsize = (14,12))\nplt.title('Correlation of Numeric Features with Sale Price',y=1,size=16)\nsns.heatmap(correlation,square = True,  vmax=0.8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Heatmaps are great to detect this kind of multicollinearity situations and in problems related to feature selection like this project, it comes as an excellent exploratory tool.\n\none aspect I observed here is the 'SalePrice' correlations.As it is observed that 'GrLivArea', 'TotalBsmtSF', and 'OverallQual' saying a big 'Hello !' to SalePrice, however we cannot exclude the fact that rest of the features have some level of correlation to the SalePrice. To observe this correlation closer let us see it in Zoomed Heat Map "},{"metadata":{},"cell_type":"markdown","source":"#### SalePrice Correlation matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"k= 11\ncols = correlation.nlargest(k,'SalePrice')['SalePrice'].index\nprint(cols)\ncm = np.corrcoef(train[cols].values.T)\nf , ax = plt.subplots(figsize = (14,12))\nsns.heatmap(cm, vmax=.8, linewidths=0.01,square=True,annot=True,cmap='viridis',\n            linecolor=\"white\",xticklabels = cols.values ,annot_kws = {'size':12},yticklabels = cols.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above zoomed heatmap it is observed that GarageCars & GarageArea are closely correlated .\nSimilarly TotalBsmtSF and 1stFlrSF are also closely correlated.\n"},{"metadata":{},"cell_type":"markdown","source":"### Pair Plot \n\n#### Pair Plot between 'SalePrice' and correlated variables\n\nVisualisation of 'OverallQual','TotalBsmtSF','GrLivArea','GarageArea','FullBath','YearBuilt','YearRemodAdd' features \nwith respect to SalePrice in the form of pair plot & scatter pair plot for better understanding."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\ncolumns = ['SalePrice','OverallQual','TotalBsmtSF','GrLivArea','GarageArea','FullBath','YearBuilt','YearRemodAdd']\nsns.pairplot(train[columns],size = 2 ,kind ='scatter',diag_kind='kde')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"saleprice_overall_quality= train.pivot_table(index ='OverallQual',values = 'SalePrice', aggfunc = np.median)\nsaleprice_overall_quality.plot(kind = 'bar',color = 'blue')\nplt.xlabel('Overall Quality')\nplt.ylabel('Median Sale Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Box plot - OverallQual"},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'OverallQual'\ndata = pd.concat([train['SalePrice'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(12, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Box plot - Neighborhood"},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'Neighborhood'\ndata = pd.concat([train['SalePrice'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 10))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nxt = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Housing Price vs Sales\n\n- Sale Type & Condition\n- Sales Seasonality"},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'SaleType'\ndata = pd.concat([train['SalePrice'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 10))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nxt = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'SaleCondition'\ndata = pd.concat([train['SalePrice'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 10))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nxt = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Missing Value Analysis \n \nWe will first check the percentage of missing values present in each feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking percentage of missing values\ndata = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\nfeatures_with_na=[features for features in data.columns if data[features].isnull().sum()>1]\nfor feature in features_with_na:\n    print(feature, np.round(data[feature].isnull().mean(), 4),  ' % of Missing Values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test data\ndata_out = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\nfeatures_with_na=[features for features in data_out.columns if data[features].isnull().sum()>1]\nfor feature in features_with_na:\n    print(feature, np.round(data_out[feature].isnull().mean(), 4),  ' % of Missing Values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features with some missing values with sales Price\nfor feature in features_with_na:\n    dataset = data.copy()\n    dataset[feature] = np.where(dataset[feature].isnull(), 1, 0)\n   \n    # Calculate the mean of SalePrice where the information is missing or present\n    dataset.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Deleting outliers\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n\n#Check the graphic again\nfig, ax = plt.subplots()\nax.scatter(train['GrLivArea'], train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Deleting Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','PoolQC','MiscFeature','Alley','Fence','FireplaceQu','Neighborhood','LotFrontage','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','GarageYrBlt', 'GarageArea', 'GarageCars','MasVnrType','MasVnrArea','MSZoning','Electrical','Utilities','Functional','KitchenQual','Exterior1st','Exterior2nd','SaleType','MSSubClass'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.dropna(axis=1)\ntest=test.dropna(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train data\nsum([True for idx,row in train.iterrows() if any(row.isnull())])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test data\nsum([True for idx,row in test.iterrows() if any(row.isnull())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert categorical variable into dummy\ntrain = pd.get_dummies(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.get_dummies(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Deleting different columns from test in train"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = np.intersect1d(test.columns, train.columns)\nprint (a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_common=train[a]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=test[a]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_common.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train_common\nY=y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max_scaler = preprocessing.MinMaxScaler()\nX_scale = min_max_scaler.fit_transform(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)\nprint(\"X_train's shape : \",X_train.shape)\nprint(\"X_test's shape : \",X_test.shape)\nprint(\"Y_train's shape : \",Y_train.shape)\nprint(\"Y_test's shape : \",Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{},"cell_type":"markdown","source":"### Linear Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LinearRegression(normalize=True)\nmodel.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc=RandomForestRegressor(n_estimators=10000, random_state=1, n_jobs=-1)\nrfc.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Interpret The Model\n\nNow the model has generated a LinearRegression model for us. Recall that a LinearRegression model consist of coefficient(s) and intercept. We can now have a look at the intercept and coefficients for our model and interpret them."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model evaluation for training set\nY_train_pred = model.predict(X_train)\nrmse = (np.sqrt(mean_squared_error(Y_train, Y_train_pred))) #root mean square error\nr2 = r2_score(Y_train, Y_train_pred) # it gives the score based on the relationship between actual output and predicted output by the model\n\nprint(\"Model training performance:\")\nprint(\"---------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\nprint(\"\\n\")\nY_test_pred=model.predict(X_test)\n# Model evaluation for testing set\nB_test_pred = model.predict(X_test)\nrmse = (np.sqrt(mean_squared_error(Y_test, Y_test_pred)))\nr2 = r2_score(Y_test, Y_test_pred)\n\nprint(\"Model testing performance:\")\nprint(\"--------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model evaluation for training set\nY_train_pred = rfc.predict(X_train)\nrmse = (np.sqrt(mean_squared_error(Y_train, Y_train_pred))) #root mean square error\nr2 = r2_score(Y_train, Y_train_pred) # it gives the score based on the relationship between actual output and predicted output by the model\n\n\n\nprint(\"Model training performance:\")\nprint(\"---------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\nprint(\"\\n\")\nY_test_pred=rfc.predict(X_test)\n# Model evaluation for testing set\nB_test_pred = model.predict(X_test)\nrmse = (np.sqrt(mean_squared_error(Y_test, Y_test_pred)))\nr2 = r2_score(Y_test, Y_test_pred)\n\nprint(\"Model testing performance:\")\nprint(\"--------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importances = pd.Series(rfc.feature_importances_, index=X_train.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n# Create a selector object that will use the random forest classifier to identify\n# It will select the features based on the importance score\nrf_sfm = SelectFromModel(rfc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_sfm = rf_sfm.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_important_train = rf_sfm.transform(X_train)\nX_important_test = rf_sfm.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_important_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new random forest classifier for the most important features\nclf_important = RandomForestRegressor(n_estimators=200, random_state=1, n_jobs=-1)\n\n# Train the new classifier on the new dataset containing the most important features\nclf_important = clf_important.fit(X_important_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model evaluation for training set\nY_train_pred = clf_important.predict(X_important_train)\nrmse = (np.sqrt(mean_squared_error(Y_train, Y_train_pred))) #root mean square error\nr2 = r2_score(Y_train, Y_train_pred) # it gives the score based on the relationship between actual output and predicted output by the model\n\n\n\nprint(\"Model training performance:\")\nprint(\"---------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\nprint(\"\\n\")\nY_test_pred=clf_important.predict(X_important_test)\n# Model evaluation for testing set\nB_test_pred = clf_important.predict(X_important_test)\nrmse = (np.sqrt(mean_squared_error(Y_test, Y_test_pred)))\nr2 = r2_score(Y_test, Y_test_pred)\n\nprint(\"Model testing performance:\")\nprint(\"--------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Output predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"output_model=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\noutput_model.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imp= rf_sfm.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output=clf_important.predict(test_imp)\nprediction=pd.DataFrame({'Id':test.Id,'SalePrice':output})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction.to_csv('prediction_c.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am simply used random forest regressor and linear regressor..If you liked this notebook upvote it....Thanks for viewing!!!"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}